{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lotto_by_fully_connected.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeroxy/lotto/blob/master/lotto_by_fully_connected.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M47_Aseiy9eM",
        "colab_type": "code",
        "outputId": "3960a2c6-3263-45c5-9468-2829f6d7acca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import tensorflow as tf\n",
        "from datetime import datetime as dt\n",
        "from joblib import Parallel, delayed, cpu_count\n",
        "from itertools import permutations as comb\n",
        "import numpy as np\n",
        "np.set_printoptions(precision=8, suppress=True, linewidth=120, threshold=np.inf)\n",
        "np.seterr(all=\"ignore\")\n",
        "\n",
        "with np.load('gdrive/My Drive/lotto/lottos_db.npz') as a :\n",
        "#with np.load('lottos_db.npz') as a :\n",
        "    lottos = a['lottos']\n",
        "    bonus = a['add_lottos']\n",
        "\n",
        "data = lottos - bonus\n",
        "neg_data = 1-data\n",
        "cnted_lot = np.ones_like(neg_data)\n",
        "cnted_lot[0] *= neg_data[0]\n",
        "for  i in range(1, neg_data.shape[0]):\n",
        "    cnted_lot[i] += cnted_lot[i-1]\n",
        "    cnted_lot[i] *= neg_data[i]\n",
        "print(f'{cnted_lot[:2,:30]}\\n{data[:2,:30]}')\n",
        "print(f'{cnted_lot[-1:,:30]}\\n{data[-1:,:30]}')\n",
        "\n",
        "traindataset = 810\n",
        "#testidx = np.random.choice(data.shape[0]-1, data.shape[0]-1-traindataset, replace=False)\n",
        "#trainidx = np.delete(np.arange(data.shape[0]-1),testidx)\n",
        "trainidx = np.arange(traindataset)\n",
        "testidx = np.arange(traindataset, data.shape[0]-1)\n",
        "\n",
        "np.random.shuffle(trainidx)\n",
        "np.random.shuffle(testidx)\n",
        "\n",
        "#trainidx=np.reshape(trainidx, (-1, traindataset))\n",
        "\n",
        "def correct_test(pb, bias, y_, testtime):\n",
        "    count = np.zeros((pb.shape[0],7),dtype=np.int32)\n",
        "    pb = pb / np.sum(pb, axis=1).reshape((-1,1))\n",
        "    pb += bias\n",
        "    pb = pb / np.sum(pb, axis=1).reshape((-1,1))\n",
        "    for i in range(pb.shape[0]):\n",
        "        real = np.where(y_[i])[0]\n",
        "        for f in range(testtime):\n",
        "            virtual = np.random.choice(45,6, replace=False, p = pb[i])\n",
        "            include = np.sum(np.in1d(virtual, real))\n",
        "            count[i, include]+=1\n",
        "    return count\n",
        "\n",
        "cpucnt = cpu_count()\n",
        "multipool = Parallel(n_jobs=(cpucnt*2), backend='multiprocessing')\n",
        "poolfn = delayed(correct_test)\n",
        "\n",
        "money = np.asarray([0,0,0,5,50,1700,50000])\n",
        "testtimes = 1000\n",
        "\n",
        "bias_sample = np.arange(0.000, 0.00002, 0.0001)\n",
        "lr = 0.0002\n",
        "\n",
        "data_desc = f'train = {trainidx.shape}, test = {testidx.shape}, all data = {lottos.shape}'\n",
        "model_desc = f'lr = {lr}, bias sample = {bias_sample}'\n",
        "print(model_desc+'\\n'+data_desc)\n",
        "\n",
        "x = tf.placeholder(tf.float32, shape=(None, 45))\n",
        "y = tf.placeholder(tf.float32, shape=(None, 45))\n",
        "\n",
        "channels = [128,256,1024]\n",
        "layer_type = []\n",
        "for i in channels:\n",
        "    layer_type.append(('fc',i,0.01))\n",
        "    layer_type.append(('fc',i,0.))\n",
        "layer_type.append(('dr',0.5,0.5))\n",
        "layer_type.append(('dr',0.7,0.7))\n",
        "print(layer_type)\n",
        "\n",
        "nets = {}\n",
        "combnum = 4\n",
        "def net(layer, is_training, reuse):\n",
        "    #layer = tf.expand_dims(layer, -1, name=\"expand\")\n",
        "    #flatten_layer = tf.layers.flatten(layer, name=\"flatten\")\n",
        "    for e in range(combnum):\n",
        "        li = list(comb(layer_type,e))\n",
        "        print(f'{e} ==> {len(li)}')\n",
        "        for row in li:\n",
        "            key = 'lot'+\"_\".join([f'{r[0]}{r[1]}-{r[2]}' for r in row])\n",
        "            with tf.variable_scope(key, reuse=reuse):\n",
        "                nets[key]= tf.layers.flatten(layer, name=\"flatten\")\n",
        "                for idx,(ltype,chan,rate) in enumerate(row):\n",
        "                    if ltype=='fc':\n",
        "                        if rate == 0.:\n",
        "                            nets[key] = tf.layers.dense(nets[key], chan , activation=tf.nn.sigmoid, trainable=is_training, name=f\"fc{idx}\")\n",
        "                        else:\n",
        "                            nets[key] = tf.layers.dense(nets[key], chan , activation=tf.nn.sigmoid, trainable=is_training, name=f\"fc{idx}\",\n",
        "                                                      kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=rate))\n",
        "                    elif ltype=='dr':\n",
        "                        nets[key] = tf.layers.dropout(nets[key], rate=rate , training=is_training, name=f\"dr{idx}\")\n",
        "                nets[key] = tf.layers.dense(nets[key], 45 , activation=tf.nn.sigmoid, trainable=is_training, name=f\"fc_fin\")\n",
        "    return nets\n",
        "\n",
        "trainnets = net(x, True, False)\n",
        "testnets = net(x,False, True)\n",
        "loss = {}\n",
        "trainjob = {}\n",
        "starttime = dt.now()\n",
        "\n",
        "for idx,k in enumerate(nets.keys()):\n",
        "    loss[k] = tf.losses.mean_squared_error(y, trainnets[k]) + tf.losses.get_regularization_loss(scope=k, name=f'{k}_reg_loss')\n",
        "    trainjob[k] = tf.train.RMSPropOptimizer(learning_rate=lr).minimize(loss[k])\n",
        "    if idx%10 == 0:\n",
        "        print(f'\\r{idx} / {len(nets.keys())}   {dt.now() - starttime}', end='')\n",
        "    #trainjob[k] = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss[k])\n",
        "\n",
        "\n",
        "\n",
        "config = tf.ConfigProto()\n",
        "#config.gpu_options.allow_growth = True\n",
        "print(\"######\")\n",
        "#for pb_bias in bias_sample: #[0.0015, 0.002,0.0025, 0.003,0.0035, 0.004, 0.005, 0.006]: #[0.02, 0.01, 0.005, 0.002, 0.001]:\n",
        "with tf.Session(config=config) as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    print(f'\\n\\n{starttime}  -  {dt.now() - starttime}')\n",
        "    for jj in range(30):\n",
        "        for ii in range(1000):\n",
        "            trainloss ,_ = sess.run([loss, trainjob], feed_dict={x:cnted_lot[trainidx], y:data[trainidx+1]})\n",
        "            #if (k+1) % 500 == 0 :\n",
        "            print(f'\\r== {ii}==  {dt.now()-starttime}',end='')\n",
        "        #for k in nets.keys():\n",
        "        #    print(f'== {k} == loss: {trainloss[k]}')\n",
        "        print()\n",
        "\n",
        "        #### test phase!!!!! #####\n",
        "        testresult,x_, y_ = sess.run([testnets,x, y], feed_dict={x:cnted_lot[testidx], y:data[testidx+1]})\n",
        "        realtest,realx_, realy_ = sess.run([testnets,x,  y], feed_dict={x:cnted_lot[-1:], y:data[-1:]})\n",
        "        print(f'== {jj+1} ==>>> {(realx_.astype(np.int32))[0,:5]}==  {dt.now()-starttime}  {dt.now()}')\n",
        "        count = np.zeros((len(nets.keys()),len(testidx),7),dtype=np.int32) \n",
        "        for pb_bias in bias_sample:\n",
        "            returns = multipool(poolfn(testresult[k],pb_bias,y_, testtimes) for kidx,k in enumerate(nets.keys()))\n",
        "            for r in range(len(returns)):\n",
        "                count[r] = returns[r]\n",
        "            meancnt = np.mean(count, axis=1)\n",
        "            report = \"\"\n",
        "            bestreport = \"\"\n",
        "            for kidx, k in enumerate(nets.keys()):\n",
        "                tempreport = f'{k} == step : {jj+1}, pb bias :{pb_bias} ==>> {np.around(np.sum(meancnt[kidx, 3:]),2)}  '\n",
        "                tempreport += f'{np.around(np.sum(meancnt[kidx]*money),2)} won / {testtimes}  *****  {dt.now()-starttime}\\n{np.around(meancnt[kidx],2)}\\n'\n",
        "\n",
        "                #### real test phase!!!!! #####\n",
        "\n",
        "                if np.sum(meancnt[kidx,3:])>0.0280*testtimes or np.sum(meancnt[kidx]*money)>testtimes*0.3:\n",
        "                    virtual = np.zeros((10,6),dtype=np.int32)\n",
        "                    for f in range(virtual.shape[0]):\n",
        "                        pb = realtest[k][0]\n",
        "                        pb /= np.sum(pb)\n",
        "                        pb += pb_bias\n",
        "                        pb /= np.sum(pb)\n",
        "                        virtual[f] = np.sort(np.random.choice(45,6, replace=False, p = pb))+1\n",
        "                    tempreport += f'{np.unique(virtual, axis=0)}\\n'\n",
        "                    tempreport += f'{realtest[k][0] }\\n\\n'\n",
        "                    bestreport += tempreport\n",
        "                else :\n",
        "                    report += tempreport\n",
        "            #print(f'{report}\\n\\n{bestreport} \\n#############    {dt.now()-starttime}  {dt.now()}    #################\\n')\n",
        "            print(f'{bestreport} \\n#############    {dt.now()-starttime}  {dt.now()}    #################\\n')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
            " [2. 2. 2. 2. 2. 2. 2. 2. 0. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 2. 1. 2. 0. 2. 2. 2. 1. 2.]]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "lr = 0.0002, bias sample = [0.]\n",
            "train = (810,), test = (47,), all data = (858, 45)\n",
            "[('fc', 128, 0.01), ('fc', 128, 0.0), ('fc', 256, 0.01), ('fc', 256, 0.0), ('fc', 1024, 0.01), ('fc', 1024, 0.0), ('dr', 0.5, 0.5), ('dr', 0.7, 0.7)]\n",
            "0 ==> 1\n",
            "WARNING:tensorflow:From <ipython-input-1-617ad071bdbb>:87: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-1-617ad071bdbb>:97: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "1 ==> 8\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-1-617ad071bdbb>:96: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "2 ==> 56\n",
            "3 ==> 336\n",
            "0 ==> 1\n",
            "1 ==> 8\n",
            "2 ==> 56\n",
            "3 ==> 336\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "400 / 401   0:06:02.756320######\n",
            "\n",
            "\n",
            "2019-05-16 12:45:50.379985  -  0:07:03.534306\n",
            "== 157==  0:10:14.204516"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}